{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Interpretability Toolkit - Quick Start\n",
    "\n",
    "This notebook demonstrates the basic usage of the LLM Interpretability Toolkit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.core import InterpretabilityAnalyzer\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize the Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize with a small model for quick testing\n",
    "analyzer = InterpretabilityAnalyzer(model_name=\"distilgpt2\")\n",
    "\n",
    "print(f\"Model loaded: {analyzer.model_name}\")\n",
    "print(f\"Number of layers: {analyzer.model_wrapper.get_num_layers()}\")\n",
    "print(f\"Number of attention heads: {analyzer.model_wrapper.get_num_attention_heads()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze a simple sentence\n",
    "text = \"The cat sat on the mat\"\n",
    "results = analyzer.analyze(text, methods=[\"attention\", \"importance\"])\n",
    "\n",
    "print(\"Analysis completed!\")\n",
    "print(f\"Available results: {list(results.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Attention Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract attention data\n",
    "attention_data = results[\"attention\"]\n",
    "tokens = attention_data[\"tokens\"][0]  # First sequence\n",
    "\n",
    "# Get attention weights for first layer, first head\n",
    "attention_weights = torch.tensor(attention_data[\"patterns\"][0, 0, 0])\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    attention_weights.numpy(),\n",
    "    xticklabels=tokens,\n",
    "    yticklabels=tokens,\n",
    "    cmap=\"Blues\",\n",
    "    cbar_kws={\"label\": \"Attention Weight\"}\n",
    ")\n",
    "plt.title(\"Attention Pattern - Layer 0, Head 0\")\n",
    "plt.xlabel(\"To Token\")\n",
    "plt.ylabel(\"From Token\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Token Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get token importance scores\n",
    "importance_data = results[\"importance\"][\"token_importance\"]\n",
    "tokens = importance_data[\"tokens\"]\n",
    "importance_scores = torch.tensor(importance_data[\"importance_mean\"])\n",
    "\n",
    "# Plot token importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(tokens)), importance_scores.numpy())\n",
    "plt.xticks(range(len(tokens)), tokens, rotation=45)\n",
    "plt.xlabel(\"Tokens\")\n",
    "plt.ylabel(\"Importance Score\")\n",
    "plt.title(\"Token Importance for Final Prediction\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Head Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get head importance scores\n",
    "head_importance = torch.tensor(results[\"importance\"][\"head_importance\"])\n",
    "\n",
    "# Create heatmap for head importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    head_importance.numpy(),\n",
    "    cmap=\"YlOrRd\",\n",
    "    cbar_kws={\"label\": \"Importance Score\"},\n",
    "    xticklabels=[f\"Head {i}\" for i in range(head_importance.shape[1])],\n",
    "    yticklabels=[f\"Layer {i}\" for i in range(head_importance.shape[0])]\n",
    ")\n",
    "plt.title(\"Attention Head Importance Scores\")\n",
    "plt.xlabel(\"Attention Head\")\n",
    "plt.ylabel(\"Layer\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Failure Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test failure prediction on different texts\n",
    "test_texts = [\n",
    "    \"The cat sat on the mat\",\n",
    "    \"aaaaaaaaaaaaaaaaaaaaaa\",  # Repetitive text\n",
    "    \"The the the the the the\",  # Repeated words\n",
    "    \"A normal sentence with proper structure and meaning.\"\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    prediction = analyzer.predict_failure_probability(text)\n",
    "    print(f\"\\nText: '{text[:50]}...'\" if len(text) > 50 else f\"\\nText: '{text}'\")\n",
    "    print(f\"Failure probability: {prediction['failure_probability']:.2%}\")\n",
    "    print(f\"Risk level: {prediction['prediction']}\")\n",
    "    print(f\"Indicators: {', '.join(prediction['indicators']) if prediction['indicators'] else 'None'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Attention Pattern Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze attention head patterns\n",
    "pattern_results = analyzer.analyze(\n",
    "    \"The cat sat on the mat. The dog sat on the mat.\",\n",
    "    methods=[\"head_patterns\"]\n",
    ")\n",
    "\n",
    "patterns = pattern_results[\"head_patterns\"]\n",
    "print(\"Identified attention patterns:\")\n",
    "for pattern_type, heads in patterns[\"identified_patterns\"].items():\n",
    "    print(f\"\\n{pattern_type.capitalize()} pattern:\")\n",
    "    for layer, head in heads[:5]:  # Show first 5\n",
    "        print(f\"  - Layer {layer}, Head {head}\")\n",
    "    if len(heads) > 5:\n",
    "        print(f\"  ... and {len(heads) - 5} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Batch Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze multiple texts at once\n",
    "batch_texts = [\n",
    "    \"The weather is nice today.\",\n",
    "    \"Machine learning is fascinating.\",\n",
    "    \"Python is a great programming language.\"\n",
    "]\n",
    "\n",
    "batch_results = analyzer.analyze(batch_texts, methods=[\"attention\"])\n",
    "print(f\"Batch size: {batch_results['attention']['shape']['batch_size']}\")\n",
    "print(f\"Tokens per sequence: {[len(tokens) for tokens in batch_results['attention']['tokens']]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Using the API\n",
    "\n",
    "The toolkit also provides a REST API for integration with other applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how to use the API (when running)\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Note: Start the API server first with: uvicorn src.api.main:app --reload\n",
    "\n",
    "# Example API request\n",
    "api_example = {\n",
    "    \"url\": \"http://localhost:8000/analyze\",\n",
    "    \"method\": \"POST\",\n",
    "    \"headers\": {\"Content-Type\": \"application/json\"},\n",
    "    \"body\": {\n",
    "        \"text\": \"The cat sat on the mat\",\n",
    "        \"methods\": [\"attention\", \"importance\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"API Request Example:\")\n",
    "print(json.dumps(api_example, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}